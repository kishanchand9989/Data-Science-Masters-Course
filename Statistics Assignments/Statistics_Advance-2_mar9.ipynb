{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ed9fa4-8554-4c56-94f9-99dfcfad52e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kishan Chand                          Assignment                        Mar9-23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2e6ed0-81a3-4bee-8823-23ce1ba01259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53a7dc6-3d82-4745-8a82-774470a6044b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab7b9616-a1e6-48f6-99f6-8ce9c5d7d545",
   "metadata": {},
   "source": [
    "## Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c583ea69-f3bd-4a1a-ae5f-f3989fdf4a35",
   "metadata": {},
   "source": [
    "The Probability Mass Function (PMF) and Probability Density Function (PDF) are mathematical functions used to describe the probability distribution of a random variable. They provide the likelihood of specific values or intervals occurring in a discrete or continuous probability distribution, respectively.\n",
    "\n",
    "Probability Mass Function (PMF):\n",
    "\n",
    "The Probability Mass Function (PMF) is used for discrete random variables. It gives the probability that a discrete random variable takes on a specific value. The PMF assigns probabilities to individual points in the distribution.\n",
    "\n",
    "Example:\n",
    "\n",
    "\n",
    "Let's consider a fair six-sided die. The random variable X represents the outcome of rolling the die. The PMF of X can be written as:\n",
    "\n",
    "PMF(X = k) = 1/6, for k = 1, 2, 3, 4, 5, 6\n",
    "PMF(X = k) = 0, for any other value of k\n",
    "\n",
    "In this example, the PMF states that the probability of getting a specific value (k) on the die is 1/6 for each of the possible values from 1 to 6. The PMF is defined only for these specific values and is zero for any other value.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Probability Density Function (PDF):\n",
    "\n",
    "The Probability Density Function (PDF) is used for continuous random variables. It describes the probability distribution over a continuous range of values. Unlike the PMF, which assigns probabilities to specific points, the PDF assigns probabilities to intervals or ranges of values.\n",
    "\n",
    "Example:\n",
    "\n",
    "\n",
    "Let's consider a continuous random variable X that follows a standard normal distribution (mean = 0, standard deviation = 1). The PDF of X, denoted as f(x), is given by the formula:\n",
    "\n",
    "f(x) = (1 / √(2π)) * e^(-x^2/2)\n",
    "\n",
    "In this example, the PDF describes the probability distribution of X across the entire real number line. It assigns probabilities to intervals of values rather than specific points. The PDF indicates the relative likelihood of observing different values of X, with higher probabilities assigned to values closer to the mean (0) and lower probabilities assigned to values further away from the mean.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e36c35-870d-48c0-afdf-908e7915999e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "586bc50d-a9ac-4864-a6ef-270d58e0703b",
   "metadata": {},
   "source": [
    "## Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309d0df9-135e-4d82-b9fa-d0a9646e79fa",
   "metadata": {},
   "source": [
    "The Cumulative Distribution Function (CDF) is a function that describes the cumulative probability of a random variable taking on a value less than or equal to a given value. It provides the probability that a random variable is less than or equal to a specific value.\n",
    "\n",
    "The CDF is denoted as F(x) and is defined as follows:\n",
    "\n",
    "F(x) = P(X ≤ x)\n",
    "\n",
    "where X is the random variable and x is the value at which we want to evaluate the cumulative probability.\n",
    "\n",
    "Example:\n",
    "\n",
    "\n",
    "Let's consider a fair six-sided die. The random variable X represents the outcome of rolling the die. The CDF of X can be calculated as follows:\n",
    "\n",
    "CDF(X ≤ k) = P(X ≤ k) = (number of outcomes ≤ k) / (total number of outcomes)\n",
    "\n",
    "For example, let's calculate the CDF for X ≤ 3:\n",
    "\n",
    "CDF(X ≤ 3) = P(X ≤ 3) = (number of outcomes ≤ 3) / (total number of outcomes)\n",
    "\n",
    "Since the die is fair, there are 3 outcomes (1, 2, 3) that are less than or equal to 3, and there are a total of 6 possible outcomes (1, 2, 3, 4, 5, 6). Therefore:\n",
    "\n",
    "CDF(X ≤ 3) = 3 / 6 = 0.5\n",
    "\n",
    "The CDF provides the cumulative probability of observing a value less than or equal to a specific value. In this example, the CDF value of 0.5 indicates that there is a 50% probability of rolling a value less than or equal to 3 on the fair six-sided die.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3257d75c-0446-4ba3-bf0b-02efff6b981f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bb4b5bf-3b32-4fe2-b561-f5bb55ce1b66",
   "metadata": {},
   "source": [
    "\n",
    "Why is CDF used?\n",
    "The CDF is used for several purposes:\n",
    "\n",
    "1. Probability Calculation: The CDF allows us to determine the probability of a random variable taking on a value less than or equal to a specific value. This can be useful for making decisions or evaluating the likelihood of certain events.\n",
    "\n",
    "2. Quantile Calculation: The CDF can be used to find the quantiles of a distribution. Quantiles represent values that divide the distribution into equal parts. For example, the median is the 50th percentile, which can be obtained by finding the value of x for which F(x) = 0.5.\n",
    "\n",
    "3. Comparison and Ranking: The CDF enables comparisons between different random variables or distributions. By comparing the CDFs of two random variables, we can assess which variable has a higher likelihood of taking on certain values.\n",
    "\n",
    "4. Statistical Analysis: The CDF is used in statistical analysis to assess goodness-of-fit, conduct hypothesis testing, and calculate confidence intervals.\n",
    "\n",
    "In summary, the CDF provides a cumulative measure of the probability distribution, allowing us to determine the probability of a random variable being less than or equal to a specific value. It serves as a fundamental tool in probability theory, statistics, and data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b893a2c-6d4d-4f1d-9c2c-4b2bc74ee583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73a40aca-1d63-4867-a106-9201122a4544",
   "metadata": {},
   "source": [
    "## Q3: What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b525ffe-5768-48fe-9359-86227c6a7e66",
   "metadata": {},
   "source": [
    "The normal distribution, also known as the Gaussian distribution or bell curve, is widely used as a model in various fields due to its versatile properties. \n",
    "\n",
    "Here are some examples of situations where the normal distribution might be used as a model:\n",
    "\n",
    "1. Height of a Population: \n",
    "\n",
    "The heights of individuals in a population tend to follow a normal distribution. The mean and standard deviation of the normal distribution can provide insights into the average height and the variation around the mean height within the population.\n",
    "\n",
    "2. Test Scores: \n",
    "\n",
    "Test scores, such as IQ scores or standardized test scores, often exhibit a normal distribution. The mean and standard deviation of the normal distribution can provide information about the average performance and the spread of scores in the population.\n",
    "\n",
    "3. Errors in Measurements:\n",
    "\n",
    "When measurements are subject to random errors, the distribution of these errors can often be approximated by a normal distribution. The mean of the normal distribution represents the expected value of the measurement, while the standard deviation represents the measurement's uncertainty or precision.\n",
    "\n",
    "\n",
    "\n",
    "The shape of the normal distribution is determined by its two parameters: the mean (μ) and the standard deviation (σ). The mean represents the central location of the distribution, indicating the average or expected value. It determines the peak of the bell curve. The standard deviation controls the spread or dispersion of the distribution. A larger standard deviation leads to a wider and flatter distribution, while a smaller standard deviation results in a narrower and taller distribution.\n",
    "\n",
    "In summary, the normal distribution is commonly used to model various phenomena, and its parameters (mean and standard deviation) play a crucial role in determining the shape of the distribution, including the location, symmetry, and spread of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67f5d51-1d4f-400d-9882-c9389b546c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eee0b45d-f760-4d44-bc38-9f78fad05924",
   "metadata": {},
   "source": [
    "## Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b871d07-40d8-4df5-a14a-26ff67dc1734",
   "metadata": {},
   "source": [
    "The normal distribution is of great importance in various fields due to its mathematical properties and its ability to model many natural and social phenomena. Here are some key reasons why the normal distribution is significant:\n",
    "\n",
    "1. Central Limit Theorem: The normal distribution plays a fundamental role in the Central Limit Theorem, which states that the sum or average of a large number of independent and identically distributed random variables tends to follow a normal distribution, regardless of the shape of the original distribution. This theorem is crucial in statistical inference and allows us to make inferences about population parameters based on sample statistics.\n",
    "\n",
    "2. Statistical Inference: Many statistical methods and tests, such as hypothesis testing, confidence intervals, and regression analysis, rely on the assumption of normality. When data approximate a normal distribution, these statistical techniques tend to be more reliable and accurate.\n",
    "\n",
    "3. Data Analysis and Modeling: The normal distribution serves as a useful model for analyzing and modeling data. It allows researchers and analysts to describe and understand the distribution of variables, assess probabilities, estimate parameters, and make predictions. It simplifies the analysis and facilitates mathematical calculations.\n",
    "\n",
    "4. Decision-Making: The normal distribution provides a basis for decision-making and risk assessment in various fields. It allows us to determine the probability of events occurring within specific ranges or thresholds, aiding in decision-making processes such as setting quality control limits, determining safety thresholds, or assessing financial risks.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b03b00-4d84-4902-97c1-f5bf18529447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6536bc64-99e0-497e-b7b2-0ffab12a3726",
   "metadata": {},
   "source": [
    "\n",
    "Real-life examples of phenomena that can be modeled by the normal distribution include:\n",
    "\n",
    "\n",
    "\n",
    "Test Scores:\n",
    " \n",
    "In standardized testing, such as IQ tests or college entrance exams, the distribution of test scores often approximates a normal distribution. This allows for meaningful interpretation of individual scores in relation to the population.\n",
    "\n",
    "\n",
    "Stock Market Returns: \n",
    "\n",
    "Daily or monthly returns of stocks or financial assets are often assumed to be normally distributed, allowing for risk assessment, portfolio management, and option pricing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c758dc8f-854f-4c34-b850-db6a9fc59e96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95836a7d-7192-4f1e-9d8d-0254ebe82970",
   "metadata": {},
   "source": [
    "## Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7434e0-ecd7-4124-8798-f0531375b642",
   "metadata": {},
   "source": [
    "The Bernoulli distribution is a discrete probability distribution that models a single binary experiment with two possible outcomes: success and failure. It is named after Jacob Bernoulli, a Swiss mathematician who introduced it in the 18th century. The distribution is characterized by a single parameter, p, which represents the probability of success.\n",
    "\n",
    "The probability mass function (PMF) of the Bernoulli distribution is given by:\n",
    "\n",
    "P(X = k) = p^k * (1 - p)^(1 - k)\n",
    "\n",
    "where X is a random variable that takes on the value of 1 for success and 0 for failure.\n",
    "\n",
    "Example:\n",
    "A common example of the Bernoulli distribution is flipping a fair coin. Let's define success as getting heads and failure as getting tails. The probability of success (getting heads) is p = 0.5, and the probability of failure (getting tails) is 1 - p = 0.5. The Bernoulli distribution for this scenario can be represented as follows:\n",
    "\n",
    "P(X = 1) = 0.5 (probability of success - heads)\n",
    "P(X = 0) = 0.5 (probability of failure - tails)\n",
    "\n",
    "In this example, the Bernoulli distribution allows us to calculate the probability of obtaining heads or tails when flipping a fair coin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5765797-21e7-40e5-bc69-f4381ea4dfa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76379084-a204-4db5-a07e-44afd7a16ffd",
   "metadata": {},
   "source": [
    "\n",
    "Difference between Bernoulli Distribution and Binomial Distribution:\n",
    "The Bernoulli distribution is a special case of the binomial distribution. The key difference between the two distributions lies in the number of trials involved.\n",
    "\n",
    "1. Bernoulli Distribution: The Bernoulli distribution models a single binary experiment with two possible outcomes (success and failure). It is characterized by a single parameter, p, representing the probability of success. The random variable can take only two values: 0 (failure) or 1 (success).\n",
    "\n",
    "2. Binomial Distribution: The binomial distribution models the number of successes in a fixed number of independent Bernoulli trials. It is characterized by two parameters: n, representing the number of trials, and p, representing the probability of success in each trial. The random variable in the binomial distribution represents the count of successes and can take on values from 0 to n.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed389c37-3f25-4dff-99ae-6a0e585a2fac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad1eb4d5-e6eb-4bcf-9db2-e841c959b123",
   "metadata": {},
   "source": [
    "## Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bca42a6-a69b-45cf-92fd-99ca444e37cd",
   "metadata": {},
   "source": [
    "To calculate the probability that a randomly selected observation from a normally distributed dataset will be greater than 60, we can use the Z-score and the standard normal distribution.\n",
    "\n",
    "The Z-score measures the number of standard deviations an observation is away from the mean. \n",
    "\n",
    "We can calculate the Z-score using the formula:\n",
    "\n",
    "Z = (X - μ) / σ\n",
    "\n",
    "Calculating the Z-score:\n",
    "Z = (60 - 50) / 10\n",
    "Z = 1\n",
    "\n",
    "Once we have the Z-score, we can use a standard normal distribution table or a statistical software to find the corresponding probability. The probability of a Z-score being greater than 1 can be found by subtracting the cumulative probability up to Z=1 from 1.\n",
    "\n",
    "P(Z > 1) = 1 - P(Z <= 1)\n",
    "\n",
    "Using a standard normal distribution table or statistical software, we can find that P(Z <= 1) is approximately 0.8413.\n",
    "\n",
    "P(Z > 1) = 1 - 0.8413\n",
    "P(Z > 1) ≈ 0.1587\n",
    "\n",
    "Therefore, the probability that a randomly selected observation from a normally distributed dataset with a mean of 50 and a standard deviation of 10 will be greater than 60 is approximately 0.1587 or 15.87%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ba2d00-2b08-41c1-975e-04afe525e93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "554cb378-c384-4e82-a662-e637a1206536",
   "metadata": {},
   "source": [
    "## Q7: Explain uniform Distribution with an example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff86a1c-9705-4311-b4a4-da05c5da201c",
   "metadata": {},
   "source": [
    "The uniform distribution is a probability distribution that describes a situation where all possible outcomes have an equal likelihood of occurring. In other words, it represents a situation where every value within a given range has the same probability of being observed.\n",
    "\n",
    "The probability density function (PDF) of a continuous uniform distribution is defined as:\n",
    "\n",
    "f(x) = 1 / (b - a)   for a ≤ x ≤ b\n",
    "\n",
    "where a and b are the lower and upper limits of the distribution, respectively.\n",
    "\n",
    "Example:\n",
    "Let's consider a scenario where a fair six-sided die is rolled. The outcome of rolling the die can be modeled using a uniform distribution because each face (1, 2, 3, 4, 5, and 6) has an equal probability of being observed.\n",
    "\n",
    "In this case, the range of the uniform distribution is from a = 1 to b = 6, representing the possible outcomes of rolling the die.\n",
    "\n",
    "The PDF of the uniform distribution in this example is:\n",
    "\n",
    "f(x) = 1 / (6 - 1) = 1 / 5   for 1 ≤ x ≤ 6\n",
    "\n",
    "This means that each value from 1 to 6 has a probability of 1/5, or 0.2, of being rolled.\n",
    "\n",
    "In the uniform distribution, the probability is evenly spread across the range of possible outcomes. There are no peaks or valleys in the distribution, and all values have equal probability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cac1779-e06f-4cab-ac17-2f763ad7bd3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6478cd91-6301-4a80-9d54-031c18338c62",
   "metadata": {},
   "source": [
    "## Q8: What is the z score? State the importance of the z score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff07c0c9-7c5c-4271-b4c4-b4fdc74d18eb",
   "metadata": {},
   "source": [
    "The z-score, also known as the standard score, is a measure that indicates how many standard deviations a data point is away from the mean of a distribution. It is used to standardize data and compare individual observations to the overall distribution.\n",
    "\n",
    "The formula to calculate the z-score for a data point x in a distribution with mean μ and standard deviation σ is:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "Here's the importance of the z-score:\n",
    "\n",
    "1. Standardization: The z-score standardizes data by transforming it into a common scale. It allows for meaningful comparisons between different datasets that may have different scales and units. By standardizing data, we can understand how each observation compares to the overall distribution and identify outliers or extreme values.\n",
    "\n",
    "2. Normal distribution: The z-score is particularly useful when dealing with normally distributed data. In a standard normal distribution (mean = 0, standard deviation = 1), the z-score directly represents the position of an observation within the distribution. It helps determine the probability associated with a particular value or range of values using z-tables or statistical software.\n",
    "\n",
    "3. Data analysis and inference: Z-scores are commonly used in hypothesis testing, confidence intervals, and statistical inference. By comparing the z-score of an observation to critical values or cutoff points, we can make decisions about hypotheses, perform significance tests, and assess the probability of an event occurring.\n",
    "\n",
    "4. Outlier detection: Z-scores are useful in identifying outliers in a dataset. Observations with z-scores that fall beyond a certain threshold (e.g., 2 or 3 standard deviations from the mean) can be considered outliers, indicating unusual or extreme values.\n",
    "\n",
    "5. Data transformation: Z-scores can be used to transform data to a normal distribution or to normalize skewed data. This transformation can be beneficial for certain statistical analyses that assume normality or require normally distributed data.\n",
    "\n",
    "Overall, the z-score is a valuable statistical tool that allows for the standardization, comparison, and interpretation of data in relation to the mean and standard deviation of a distribution. It provides a standardized measure of how an observation or data point deviates from the mean, facilitating various statistical analyses and inference procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426ecf7e-559f-4e66-b5f8-82d3ce4a7988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e5270d7-e0c6-451c-b7eb-3f80f5d2a0da",
   "metadata": {},
   "source": [
    "## Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e688e7e1-8674-455d-9b08-a536c5d1e0f1",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental theorem in probability theory and statistics. It states that the sum or average of a large number of independent and identically distributed random variables, regardless of the shape of their original distribution, will tend to follow a normal distribution. \n",
    "\n",
    "The Central Limit Theorem has several significant implications and applications:\n",
    "\n",
    "1. Normality Approximation: The CLT allows us to approximate the distribution of a sum or average of random variables by a normal distribution, even if the individual variables themselves do not follow a normal distribution. This is extremely useful because the normal distribution is well-understood and has many convenient mathematical properties.\n",
    "\n",
    "2. Statistical Inference: The CLT forms the foundation for many statistical inference techniques, such as hypothesis testing, confidence intervals, and regression analysis. It enables us to make inferences about population parameters based on sample statistics, even when the underlying distribution is unknown or not normal.\n",
    "\n",
    "3. Sample Means and Averages: The CLT implies that the sample mean or average of a large enough sample, regardless of the original distribution, will be approximately normally distributed. This is particularly useful when dealing with real-world data, as it allows us to make probabilistic statements about sample means and draw conclusions about population means.\n",
    "\n",
    "4. Sampling Distribution: The CLT helps us understand the behavior of the sampling distribution, which is the distribution of a sample statistic (such as the mean or proportion) across different samples drawn from the same population. The sampling distribution tends to become more normal as the sample size increases, which allows us to make more accurate inferences about the population parameters.\n",
    "\n",
    "5. Robustness of Statistical Tests: Many statistical tests, such as t-tests and ANOVA, rely on the assumption of normality. The CLT ensures that these tests remain valid and reliable, even if the underlying population distribution is not normal, as long as the sample size is large enough.\n",
    "\n",
    "In summary, the Central Limit Theorem is a powerful result in statistics that allows us to make accurate inferences about population parameters, approximate the distribution of sample statistics, and apply a wide range of statistical methods even when the original data does not follow a normal distribution. It has immense practical significance and forms the backbone of statistical theory and practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6947fe9-a264-46d7-bcb9-d2709c571875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f67f0fd-279f-4a63-bcd5-1d450a72f520",
   "metadata": {},
   "source": [
    "## Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e668a269-344f-4eb3-ac6e-5b9e7b1c08c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "181cc4ea-6856-4d44-ac0a-63f92291f560",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) makes several assumptions in order to hold true. These assumptions are:\n",
    "\n",
    "1. Independence: The random variables being combined (summed or averaged) should be independent of each other. This means that the outcome of one variable does not affect the outcome of another. Independence is crucial for the CLT to apply.\n",
    "\n",
    "2. Identically Distributed: The random variables should be identically distributed, meaning they have the same probability distribution. This implies that they have the same mean and variance.\n",
    "\n",
    "3. Finite Variance: The random variables should have a finite variance. If the variance is infinite or undefined, the CLT may not hold. Having a finite variance ensures that the sample mean or average is well-behaved.\n",
    "\n",
    "4. Sample Size: The CLT assumes that the sample size is sufficiently large. There is no fixed threshold for what constitutes a \"large\" sample size, but a general guideline is that the sample size should typically be greater than 30 for the CLT to work well. However, the actual sample size required may depend on the specific characteristics of the underlying distribution.\n",
    "\n",
    "It's important to note that while these assumptions are necessary for the CLT to hold, they are not always strictly satisfied in practice. In some cases, the CLT may still provide a reasonable approximation even if the assumptions are only partially met. Additionally, modifications and extensions of the CLT exist to relax certain assumptions or to address specific scenarios where the original assumptions may not be fully met.\n",
    "\n",
    "However, it is crucial to consider these assumptions when applying the CLT and to assess the robustness and validity of the results based on the specific context and characteristics of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c14f09-19e3-4cd5-8ccc-7ce7d3866742",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
